# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19yNKmRMidvVs3DWDr0vFN6ifTBCjXceZ
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model
from scipy.special import expit
from sklearn.model_selection import train_test_split

n_samples = 1000
np.random.seed(0)
X = np.random.normal(size=n_samples)
y = (X > 0).astype(np.float)
X[X > 0] *= 4
X += .3 * np.random.normal(size=n_samples)
X = X[:, np.newaxis]

plt.scatter(X, y)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit the classifier
clf = linear_model.LogisticRegression(C=1e5, solver='lbfgs')
clf.fit(X_train, y_train)

clf.score(X_test,y_test)

y_pred = clf.predict(X_test)

# plt.scatter(X_test, y_pred)
# plt.show()

clf2 = linear_model.LinearRegression()
clf2.fit(X_train, y_train)

clf2.score(X_test,y_test)

plt.figure(1, figsize=(8, 6))
plt.clf()
plt.scatter(X.ravel(), y, color='yellow', zorder=20)

X_test = np.linspace(-5, 10, 300)

loss = expit(X_test * clf.coef_ + clf.intercept_).ravel()
plt.plot(X_test, loss, color='red', linewidth=3)

plt.plot(X_test, clf2.coef_ * X_test + clf2.intercept_, linewidth=1, color='green',)
plt.axhline(.5, color='.5')

plt.ylabel('y')
plt.xlabel('X')
plt.xticks(range(-5, 10))
plt.yticks([0, 0.5, 1])
plt.ylim(-.25, 1.25)
plt.xlim(-4, 10)
plt.legend(('Logistic Regression Model', 'Linear Regression Model'),
           loc="lower right", fontsize='medium')
plt.tight_layout()
plt.show()

